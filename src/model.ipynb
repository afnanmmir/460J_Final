{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 15:47:03.184200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input, n_vocab):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        units=512,\n",
    "        input_shape = (input.shape[1], input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3))\n",
    "\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "\n",
    "    #if using weights-improvement-188-0.0081-bigger.hdf5 weights, comment out the following lines\n",
    "    #if using weights-improvement-100.hdf5 weights, uncomment the following lines\n",
    "    # model.add(Dense(n_vocab))\n",
    "    # model.add(Dropout(0.3))\n",
    "    # model.add(Dense(n_vocab))\n",
    "    # model.add(Dropout(0.3))\n",
    "    #endif\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 15:47:19.094821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 15:47:19.096510: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 44s 3s/step - loss: 4.7640\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 4.8242\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.6474\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 4.6178\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.5835\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.6420\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.5665\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 35s 3s/step - loss: 4.5648\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.5342\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.5415\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.5285\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 4.5184\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 28s 2s/step - loss: 4.4555\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.4529\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.4446\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 4.5383\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.4068\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 21s 2s/step - loss: 4.3800\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.3940\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.3489\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.3544\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.3745\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.3601\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 21s 2s/step - loss: 4.2967\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.2770\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.2883\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.3194\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.2733\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.2550\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.2779\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 4.2423\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 4.1665\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.2007\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.1791\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.1917\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.1844\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.1796\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.0596\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.1098\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.0504\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.0961\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 3.9941\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.0177\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 4.0248\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 3.9733\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 3.9387\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.9195\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.8800\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 3.8840\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.7637\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 3.8796\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 3.8490\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 3.8042\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.7463\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.6629\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.6394\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.6369\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 3.5730\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 3.5732\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.4641\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.4455\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 3.3946\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 3.5489\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 3.3234\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 3.3739\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.3335\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.2243\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 3.2036\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 22s 2s/step - loss: 3.1631\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 3.1625\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 3.1130\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 3.1408\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 38s 3s/step - loss: 3.2105\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 84s 7s/step - loss: 3.0137\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 72s 6s/step - loss: 3.0271\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 71s 7s/step - loss: 2.9849\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 2.9995\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 2.8412\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 2.7975\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 73s 7s/step - loss: 2.7627\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.9018\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 74s 7s/step - loss: 2.7792\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 59s 5s/step - loss: 2.6470\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 42s 4s/step - loss: 2.6756\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 43s 4s/step - loss: 2.7730\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 46s 4s/step - loss: 2.5970\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 56s 5s/step - loss: 2.7440\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.5871\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.4484\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 2.5318\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.7124\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.5685\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 2.4372\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 35s 3s/step - loss: 2.4563\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 36s 3s/step - loss: 2.4841\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 2.4487\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 2.4797\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 23s 2s/step - loss: 2.4435\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.3924\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 2.2549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3808131df0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../data/network_input','rb') as file:\n",
    "    network_input = pickle.load(file)\n",
    "with open('../data/network_output','rb') as file:\n",
    "    network_output = pickle.load(file)\n",
    "with open('../data/notes','rb') as file:\n",
    "    notes = pickle.load(file)\n",
    "\n",
    "num_vocab = len(set(notes))\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]\n",
    "model = create_model(network_input,num_vocab)\n",
    "model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_output.mid'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/network_input','rb') as file:\n",
    "    network_input = pickle.load(file)\n",
    "with open('../data/network_output','rb') as file:\n",
    "    network_output = pickle.load(file)\n",
    "with open('../data/notes','rb') as file:\n",
    "    notes = pickle.load(file)\n",
    "with open('../data/note_dict','rb') as file:\n",
    "    note_dict = pickle.load(file)\n",
    "with open('../data/pitch_names','rb') as file:\n",
    "    pitch_names = pickle.load(file)\n",
    "\n",
    "\n",
    "model = create_model(network_input,num_vocab)\n",
    "model.load_weights(\"weights-improvement-188-0.0081-bigger.hdf5\")\n",
    "# model.load_weights(\"weights-improvement-100.hdf5\")\n",
    "\n",
    "\n",
    "startIndex = np.random.randint(0,len(network_input)-1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitch_names))\n",
    "pattern = network_input[startIndex]\n",
    "prediction_output = []\n",
    "\n",
    "for i in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(num_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    prediction_output.append(result)\n",
    "    pattern = np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "offset = 0\n",
    "output_notes = []\n",
    "for pattern in prediction_output:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='test_output.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('EE460JHW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b3a8f16b512bfb84c1a5885d1b11ac5366e52dde88f514fe166182a800757bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
